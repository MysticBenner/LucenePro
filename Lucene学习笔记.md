##### **一.什么是全文检索？**

###### 1.数据的分类

- 结构化数据

  格式固定、长度固定、数据类型固定。例如数据库中的数据

- 非结构化数据

  格式不固定、长度不固定、数据类型不固定。例如word、pdf、邮件以及html文件

###### 2.数据的查询

- 结构化数据的查询

  sql语句，查询结构化数据的方法，简单，数据快

- 非结构化数据的查询

  例如：从文本文件中找出包含spring单词的文件

  ​	1.目测法；2.使用程序把文件读取到内存中，再匹配字符串（这两种方法基于不是很大的文件）

  ​	3.把这个非结构化数据变成结构化数据再进行查询

  ​	先跟进空格进行字符串拆分，得到一个单词列表，基于单词列表创建一个**索引**。然后根据索引，根据单词和文档的对应关系找到文档列表，这个过程就叫做全文检索。 

  ​	**索引：**一个为了提高查询速度，创建某种数据结构的集合。

**3.全文检索**

​	先创建索引然后查询索引的过程叫做全文检索。索引一次可以多次创建，表现为每次查询速度很快。



##### 二.全文检索的应用场景

###### 1.搜索引擎

###### 2.站内搜索

###### 3.电商搜索



##### 三.什么是Lucene

Lucene是一个基于Java开发的全文检索工具



##### 四.Lucene的实现过程

**1.创建索引**

- 获得文档

  原始文档：要基于哪些数据进行搜索，这些数据就是原始文档。

  搜索引擎：使用爬虫获取原始文档

  站内搜索：数据库中的数据

  案例：使用io流读取磁盘上的文件

- 创建一个文档对象

  对应的每个文档创建一个Document对象

  每个document对象中包含多个域（field）

  域中保存的是原始文档数据

  - 域的名称
  - 域的值

  没个文档中还包含着唯一的编号，即文档id

- 分析文档

  即分词的过程

  - 根据空格进行字符串拆分，得到一个单词列表
  - 把单词统一转化为小写
  - 去掉标点符号
  - 去掉停用词 停用词：无意义的词

  每个关键词都封装成一个Term对象中，Term中包含两个内容：1.关键词所在的域；2.关键词本身。

  不同的域中拆分出来的相同的关键词是不同的Term。

- 创建索引

  基于关键词列表创建一个索引，保存到索引库中。

  索引库中包含：

  1.索引；2.document对象；3.关键词和文档的对应关系

  通过词语找文档，这种索引的结构叫做**倒排索引结构**。

**2.查询索引**

- 用户查询接口

  用户输入查询的地方

- 把关键词封装为一个查询对象

  找到要查询的域和要查询的关键词

- 执行查询

  将要查询的关键词到对应域上进行搜索。找到关键词，根据关键词找到对应的文档

- 渲染结果

  根据文档id找到文档对象、对关键词进行处理、分页处理以及最终展示

##### 五.入门程序

**1.创建索引**

- 环境搭建

  创建一个Java工程

  添加jar包

  - lucene-analyzers-common-8.3.0.jar
  - lucene-core-8.3.0.jar
  - common-io.jar

- 步骤：

  - 创建一个Directory对象，指定索引库保存的地址
  - 基于Directory对象创建一个Indexwrite对象
  - 读取磁盘上的文件，对应每个文件创建一个对象
  - 向文档对象中添加域
  - 把文档对象写入索引库
  - 关闭Indexwrite对象

**2.查看索引**

使用luke查看索引

**3.查询索引库**

- 创建一个Directory对象，指定索引库的位置
- 创建一个IndexReader对象
- 创建一个IndexSearcher对象，构造方法中的参数indexReader对象
- 创建一个Query对象，TermQuery
- 进行查询，得到一个TopDocs对象
- 取查询结果的总记录数
- 取文档列表
- 打印文档中的内容
- 关闭IndexReader对象

##### 六.分析器

默认使用的是标准分析器StandardAnalyzer

1.查看分析器的分析效果

使用Analyzer对象的tokenStream方法返回一个TokenStream对象，词对象中包含了最终的分词结果

步骤：

- 创建一个Analyzer对象，StandardAnalyzer对象
- 使用分析器对象的tokenStream方法获得一个TokenStream对象
- 向TokenStream对象设置一个引用，相当于数一个指针
- 调用TokenStream对象的reset方法，如果不调用抛出异常
- 使用while循环遍历TokenStream对象
- 关闭TokenStream对象

2.IEAnalyzer的使用

一定要选择合适的版本进行表示

- 将.IEAnalyzer的jar包添加到工程中

- 把配置文件和扩展词典放到classpath下

  注意：扩展词典是禁用windows记事本编辑器打开查看的

  扩展词典：添加了一些新词

  停用词词典：无意义的词或者敏感的词汇

##### 七.索引库维护

**1.添加文档**

**2.删除文档**

- 删除所有文档
- 删除包含指定字段的文档

**3.修改文档**

原理：先删除旧文档再添加新的文档

##### 八.索引库查询

1.使用Query的子类

- TermQuery

  根据关键词进行查询，需要指定查询的域和要查询的关键词

- RangeQuery

  根据范围进行查询

- 使用QueryParse进行查询

  可以对要查询的内容进行分词，再基于分词结果进行查询

  添加一个jar包 lucene-queryparser-7.4.0.jar



Lucene至此基本知识已经结束

下面是基于Lucene的查询服务器，主要有Solr和Elasticsearch两种，solr和elasticsearch都是基于Lucene包做的一些封装。

Solr是一个有HTTP接口的基于Lucene的查询服务器，封装了很多Lucene细节，自己的应用可以直接利用诸如 .../solr?q=abc 这样的HTTP GET/POST请求去查询，维护修改索引。

Elasticsearch也是一个建立在全文搜索引擎 Apache Lucene基础上的搜索引擎。采用的策略是分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。

Lucene使用上更加灵活，但是你需要自己处理搜素引擎系统架构，以及其他附加附加功能的实现。而Solr帮你做了更多，但是是一个处于高层的框架，Lucene很多新特性不能及时向上透传，所以有时候可能发现需要一个功能，Lucene是支持的，但是Solr上已经看不到相关接口。


##### 三者之间的区别

首先说明三者之间的一个联系：solr和elasticsearch都是基于Lucene实现的！
其次
solr利用zookpper进行分布式管理，而elasticsearch自身带有分布式协调管理功能；
solr比elasticsearch实现更加全面，solr官方提供的工恩能够更多，而elasticsearch本身更注 重于核心功能，高级功能多由第三方插件提供；
solr在传统的搜索应用中表现好于elasticsearch，而elasticsearch在实时搜索应用方面比solr表现好！




































































